<!DOCTYPE html>
<html>
<head>
<title>Artificial intelligence never has a headache</title>
<meta name="description" content="Following all the developments in technology I often feel overwhelmed and start to compare myself to an AI implementation. Also, the data-driven lifestyle emerges, and a human body is viewed as a set of parameters not only by scientists, but also by us, ordinary individuals. 
The fear of AI comes from a concept that AI is comparable to human intelligence, and therefore superiour. We are afraid that we will be run over by another species. But in fact, we are not comparable. So in my thesis i research the value of the human body, comparing my own functionality to an AI and ask  What are the profits of existing as a human being, and what are the benefits of having a body in the current digital workflow?">
<meta property="dc:creator" content="Karina Zavidova"/>
<meta property="og:title" content="Artifcial intelligence never has a headache"/>



	<meta charset="utf-8">
	<link rel="stylesheet" type="text/css" href="style.css">
	<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css">


</head>
<body>
<div class="navig"><a href="menu.html"><i class="fa fa-caret-left"><h3>menu</h3></i></a></div>
<h1>Artificial intelligence never has a headache</h1>
<div class="content">

<div class="images">
	<div class="scroller">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">
<img src="media/img.jpg">

	</div>
	</div> 


	<div class="text">
	<div class="scroller">

<h2>Chapter one</h2>
<p>	
When I first started writing my thesis, the initial intention was to study and analyze the strategies of
decisionmaking.
Picking such an abstract and broad topic required a lot of research and narrowing down to
the seizable amount of knowledge. The problem is, that while writing about choices, selection methods and
filtering information, I...couldn’t decide what exactly am I writing about. A mechanism of making a single
decision bothers and puzzles me so much because as a designer I am eager to attempt seeing an
underlying pattern. But, with all the efforts I take, it does not reveal itself.
Graphic design works with wast amounts of information and partly consists of building structures,
patterns and templates. During three years I have been studying this discipline I became fascinated with the
ways designers work with information: organizing enormous amounts of data and creating complex schemes
to sort, digest and display it. Reducing information flows to a rather visual message requires a lot of rational
thinking and reasoning. We are taught to create frameworks to fragment and make “the big thing” digestible,
and there is so much beauty in processing intricate experiences into a single visual message.
Being taught all this, I do not see this experiences affecting my daily life and wonder if the tools of
design can be applied to the routine tasks in an intuitive and playful way.
Overwhelmed with choices and decisions to make, I represent the target audience of all the
productivity software and techniques. As I am writing this text, the Pomodoro technique app is counting the
time. Besides Pomodoro, word count tool is keeping me on track of the fewthousandwordsthesis,
period
tracker app shows that craving chocolate today is purely hormonal (so I should get some to be more
productive in my writing) and I also track my activity, moves and headaches. All of this for the sake of being
more productive . Does being that informed helps to make the right choice? No.
Choosing is so complicated because the perfect decision is a product of balance between two
extremities: One is making fast decisions without contemplation, second is the opposite taking
very long
time and a lot of efforts to make the best choice, which may lead to paralyzing indecisiveness.
The number of tools is escalating, so the search of balance in the sake of productivity helps to
spawn more and more apps on the already saturated market. Instead of modifying my routine in order to
enable it to structure itself, I get clogged in the labyrinth of various methods and solutions.
Numerous planners and trackers remind me that I have a serious tasks to complete and deciding
and actually doing things becomes a burden. In his book Homo Ludens Johan Huizinga writes that the
highest concentration and dedication to the process happens, when the process is wrapped in the structure
of a game. Paradoxically, playing becomes the most serious process. The players are aware that they are
playing the game, but instead of burden of decisionmaking
‘in the real world’ they concentrate on an actual
task.
Beauty and elegance of a designed gameplay structure gives the comfort and protects me from the
uneasiness of the ‘real world’. What if ‘taking things seriously’ in a solemn and adult way is just creating
numerous obstacles? Maybe there should be a technique focused on removing the stressful part of making
a decision?
When looking at the existing iOS lifestyle applications, I see two extremities: There are socalled
productivity apps, which goal is to stimulate the user to achieve the desired result. There are planners,
somewhere in between two extremities, because they are neutral towards the achievement of goals but also
they have system of reminders to keep constantly on track with the status of the task. And, the opposite,
there are meditation and relaxation apps.
Isn’t it bizarre that there are applications to manage one’s anxiety in the environment where
reminders and timers and trackers and updates are inducing it at the very same time?
Embracing the development of our operational systems and upgrades of our devices we are
approaching singularity . How would we coexist with the machine mind? Will it help solving our routine
problems? As Douglas Rushkoff writes in his book “Program or be programmed” instead of upgrading
technology for humans we upgrade ourselves for machinery.
We trust our planners and apps to help us decide how to live, counting technology as an equal to
human mind, which is not true. Computers exceed us in capabilities of calculation (the original purpose of a
computer ), but they have no knowledge of paradox or serendipity.
Will the machine help me to sort my issues, will technology be my therapist? In a perfect world I can
be human and do my ‘human thing’ and let the machine organize me.
The illusion of human to human interaction with the machine is called the ELIZA effect. ELIZA is a
computer program, written at MIT by Joseph Weizenbaum between 1964 and 1966. It was designed to
simulate a humanlike
conversation, based on processing user responses to scripts. The script DOCTOR
was designed to simulate a conversation with a psychotherapist. It was one of the first chatterbots.</p>
<p>Chatterbot (or bot) is a program, which purpose is to have a conversation with a human. Chat bot is able to
pass the Turing test, by simply fooling the human.
ELIZA is such a milestone in development of an artificial intelligence because it was the first time
when the goal of a programmer was to create an illusion of humanhuman
interaction.
Weizenbaum noticed that humans tend to bond emotionally with the machines, and unlikely the car
or a musical instrument, computer affects the thinking and behaviour. In the 1976 article "Computer Power
and Human Reason” he writes about people who experienced emotional bonding with the program he wrote:
“I was promptly bombarded with accusations that what I proposed amounted to spying on people’s most
intimate thoughts; clear evidence that people were conversing with the computer as if it were a person
who could be appropriately and usefully addressed in intimate terms. I knew of course that people form all
sorts of emotional bonds to machines, for example, to musical instruments, motorcycles, and cars. And i
knew from long experience that the strong emotional ties many programmers have to their computers are
often formed after only short exposures to their machines. What I had not realized is that extremely short
exposures to a relatively simple computer program could induce powerful delusional thinking in quite
normal people. This insight led me to attach new importance to questions of the relationship between the
individual and the computer, and hence to resolve to think about them.”
In 1972 ELIZA had the first computer to computer conversation with an artificial intelligence program
named PARRY. Eliza was simulating a doctor, and Parry was built to simulate a patient, suffering from
Schizophrenia.
The machines we get attached to technically are nothing but a machine: It does not grow as a being
or assemble itself without any human administration. But in order to understand why we rely on technology
in our routine so much we need to know and remember that the machine can simulate understanding and be
perceived as a human.
Why this shift became possible only with digital technology? In the same article as cited above
Weizenbaum explains:
“...What is it about the computer that has brought the view of a man as a machine to a new level
of plausibility? Clearly there have been other machines that imitated man in various ways, e.g, steam
shovels. But not until the invention of the digital computer have there been machines that could perform
intellectual functions of even modest scope: i.e., machines that could in any sense be said to be
intelligent. Now “artificial intelligence” (AI) is a subdiscipline of computers science. This new field will have
to be discussed. Ultimately a line dividing human and machine intelligence must be drawn. If there is no
such line, then advocates of computerized psychotherapy may be merely heralds of an age in which man
has finally been recognized as nothing but a clockwork.
Then the consequences of such a reality would
need urgently to be divided and contemplated.”
This text from 1976 is so striking in 2015 because computers became portable and wearable, and
the amount of tasks we trust to the technology has dramatically increased. This raises the actuality of these
issues.</p>
2. Biohacking and design
Keywords: biohacking, hacker ethics, augmentation
Biohacking is a movement about augmenting the nature, and human body in particular, by the
means of technology. It aims to improve functionality and performance and also to give people more
freedom in designing their own life, not by managing it, but by adjusting the body to the tasks it needs to
perform. Datadriven
lifestyle, first adopted by few technology and computing enthusiasts, is getting more
and more followers. Using hacker ethics, biohacker considers human body and mind a project, which can be
developed further.
The original hacker code of morality was formed by the MIT hackers group from the late 1950’s to
late 1960’s. In his book ‘Hackers: Heroes of the computer revolution’ Steven Levy lists these rules as
follows:
1)Always yield the HandsOn
Imperative! Access to computersand
anything else which might teach you
about the way the world worksshould
be unlimited and total.
2) All information should be free.
3) Mistrust AuthorityPromote
Decentralization.
4) Hackers should be judged by their hacking, not bogus criteria such as degrees, age, race, or position.
5) You can create art and beauty on a computer.
6) Computers can change your life for the better.
Note from an Urban Dictionary article on hacker ethic says “ While many of the 1960s hackers claim that
modern hackers have rejected this code, it has actually strongly influenced all hackers for the last thirty
years.”
Rephrasing the point one, biohacking claims access to biology/our bodies/data which can be
received from selftracking.
The ideology stands for taking control of one’s health and mental condition from
the hands of doctors and therapists. It promotes educating yourself about the way our bodies work and
using intelligence, technology and logic to become an “advanced model” of an ordinary individual.
Biohacking looks for the bits of source code to the human body: In its utopian vision the approach is
perfect one
can program herself in an a renaissance man (actually, I would write “a renaissance girl”,
because I am female, but there is no such term. Girls didn’t run the world at the time), but on the other hand
an error or malware can lead to a total destruction. Humans tend to err, so on a large scale biohacking
seems like a possible doom scenario.
On a small scale, biohacking is already being implemented in our everyday life. Are the biohackers
among us? How to guess a biohacker?
It is easy to imagine a body all covered in blinking and buzzing devices and implants, as we see
these kind of images so often in the movies. We imagine wearables, because it still looks futuristic: in 2015
no one walks on the street wearing VR device or an exoskeleton. In fact, technology, which attracts attention
to itself more than to its functionality, soon becomes obsolete in our techsavvy
world. Example: the rise and
fall of Google Glass.
Biohacker of 2015 doesn’t wear any cumbersome scifi
inspired devices, she opens the door of her
office with an RFID chip, implanted in her hand, and takes a sip of her Bulletproof coffe e.
Technology becomes more subtle and seamlessly integrated in our routine. To track your body in
2015, you don’t necessarily need to implant a board under your skin (as Tim Cannon did in 2013 : He
implanted a sensor, which gets the data on his body temperature and sends it to his smartphone). There are
a lot of IPhone apps to measure and track your heartbeat, movements, activity etc.
The perception changed as well: We are eager to share our bodies through variety of social media
applications. Before Instagram, sharing a personal vision of the world through images was a prerogative of
artists: In 2007 a performance artist called Stelarc grew an earshaped
tissue out of his own stem cells, and
implanted it in his arm. Ear on Arm project’s goal was not only to grow an ear which “hears” same sounds as
two original ears, but also to make the third ear to transmit these sounds. To share his ear with others,
Stelarc had undergone two surgeries with risks and complications.
It is very different from sharing a picture of food on social networks. But if thinking only of the final
purpose, then the difference seem to disappear: Without involvement in the culture of body modification, we
grow apps, to transmit bits of world, as seen through our eyes: Take Instagram as an extension of our eyes
and ears, encapsulating the momentum and stirring the desire to share, and to rent our eyes and ears to
others, and to give the geographical coordinates, our body has been to.
Noninvasive
selftracking
and monitoring devices such as Fitbit , and other activity trackers,are
becoming mainstream. If using metaphors, this can be compared to ripped jeans: First worn by punks, they
were brought into fashion and almost dissociated with its rebellious roots. Biohacking goes from
counterculture to the popular culture.
3. Productivity and lifestyle
Keywords: productivity, tracking, count, lifelogging
Constantly monitoring the activity and behaviour such as exercising, sleeping, eating, walking or
using transport is called lifelogging. It aims to summarize data one’s body produces in order to give human
an objective image of herself. There is also a movement, called Quantified self which promotes
selfknowledge
through numbers and hold meetings and conferences on selftracking
and improving using
data. Basically, every smartphone owner is equipped for it: There is a camera to make documentation, there
is a GPS, so movements and coordinates can be tracked. It is possible to measure and keep track on
heartbeat, using a flash from the camera, there are numerous apps for tracking cycles and mental conditions
and a diarylike
apps. And the social media apps enable sharing. Lifelogging is gathering the data for
personal use and lifestreaming is aimed to share this data. A smartphone can work for both.
Chris Dancy calls himself “a mindful cyborg”. An article on Mashable.com says “ 45yearold
Chris
Dancy is known as the most connected man in the world. He has between 300 and 700 systems running
at any given time, systems that capture realtime
data about his life. His wrists are covered with a variety
of wearable technology, including the fitness wristband tracker Fitbit and the Pebble smartwatch. He
weighs himself on the Aria Wifi scale, uses smartphone controlled Hue lighting at home and sleeps on a
Beddit mattress cover to track his sleep.” As told in this interview, Chris does that to stay healthy. "I've lost
100 pounds and learned to meditate," he says. "I'm much more aware of how I respond to life and take
steps to adjust to my environment. I've also formed better habits thanks to the feedback I'm getting."
His statement is quite paradoxical in itself he
tells that the feedback he gets from the devices he’s
wearing makes him a better human. More precise and better integrated in the environment. In this case, is it
his own intention to do things he does, or the he is a cocreation
of himself and his wearables? From a point
of view of a lifelogger our data is mastering us, but on our own conditions.
Do I consider myself a lifelogger? I would say yes. Everyone who uses digital technology is
producing some amount of data without even realizing it, but I do intentionally turn my body’s activity into
digits. From the rational point of view I do it to get precise measurements and facts because I care a lot
about making the best of my own being. On the opposite, I constantly question my relationship with tech and
my own data. The adepts of self quantification say that it helps to live more efficiently, but tracking does not
always help to discover the core of the problem.
A poetic performance by Erica Scourti illustrates this duality really well: an artist uses selftracking
and productivity applications in her practice. For her performance during “Do you feel me?” symposium in
Eindhoven she used an application called Spritz to read her own poem on stage. Spritz is an application,
designed to improve the speed of reading. Its slogan is “save time, increase focus and have fun.” After
uploading the text and selecting the speed in words per minute, the app starts to spit out the words in a
selected speed and you only have to read what you see on the screen. This is an explanation of the science
behind it from the official webpage: “ Traditional reading involves publishing text in lines and moving your
eyes sequentially from word to word. For each word, the eye seeks a certain point within the word, which
we call the “Optimal Recognition Point” or ORP. After your eyes find the ORP, your brain starts to process
the meaning of the word that you’re viewing. With each new word, your eyes move, called a “saccade”,
and then your eyes seek out the ORP for that word. Once the ORP is found, processing the word for
meaning and context occurs and your eyes move to the next word. When your eyes encounter
punctuation within and between sentences, your brain is prompted to assemble all of the words that you
have read and processes them into a coherent thought.”
Starting with hundred words per minute, Erica kept gradually increasing the speed up to seven
hundred words per minute, and at the certain moment she could not keep it up with her own text. She was
reading it out loud on stage, and in the end of her performance she ran out of breath, trying to keep up with
the rhythm, the app was dictating.
Erica performed her piece on stage in front of an audience, but it is a good metaphor of the struggle
we have every day to keep up with the rhythm,which the technology we trust so much assigns to us.
The public streaming of Chris Dancy’s data shows his age at the present moment, and physical
activity for the past weeks. Also it is possible to learn where did Chris had his breakfast or lunch. It shows
steps, productivity, places he’ve been to and pictures he liked. It also includes his Tweets. Does it look like
an image of someone who has “ between 300 and 700 systems running at any given time.”
It does not, so if the information on the given amount of tracking devices is true, that means that
Chris made a digest of data he wants to display on public. Also, it may mean that he does not look at major
percent of the data he has produced. That bring back the questions about the ELIZA effect: If we are
surrounded by systems so elaborate and sensitive to us, are we willing to ask their advices? Or do we feel
that these systems may intervene our life. Do we feel the urge to protect ourselves from our applications?
In my experience of tracking various processes in my body with IOS apps I noticed that I have an
irrational fear that the application will start evaluating me. For example: My headache tracker app (Ironically
enough, called My Headache Diary ). I installed it to have more accurate information on the amount of
migraines in a month, so my doctor can find a treatment which fits the best. I stopped using it after marking
one week of daily headaches, because it felt uncomfortable. I had a feeling that after knowing this, the app
may start criticizing my lifestyle. Some apps are very direct an
app which reminds you to drink enough
water will keep buzzing until you give it the number of glasses you drank. Some apps give you the freedom
to choose what to track and what to keep to yourself. For example, period tracker app automatically counts
menstrual cycles but also has an additional menu with checkboxes for pills, sex, weight and temperature.
There are also separate menus for moods, cramps etc. Once I told to a friend about the mixed feelings I
have about using all these checkboxes and he joked that with this kind of interface this app can start a
sexcoaching
career. We laughed about it and continued talking about our human problems.
As Weizenbaum noted, even short interaction with a program could induce a “powerful delusional
thinking in quite normal people”. Point six of the previously cited hacker code of morality states that
“ Computers can change your life for the better.” Computers were designed to make complex calculations,
and they are still making calculations, but they also they are talking to us, ordinary individuals. At the times
computers were occupying the entire room, could anyone think that search algorithms would gain our trust
and start giving us advices and recommendations on a daily basis?
Side note: The pinterest experience
Keywords: Pinterest, trends, popular
Online platforms as Pinterest already give us advice on what to wear, what to cook, how to decorate
our houses and many other topics. An example of embedding the noncurated
selection in daily life is
following trending topics on such online archives. Pinterest is a collection of boards where users pin
contents from all over the web, creating a huge web archive.
One day a BuzzFeed journalist, named Rachel Wilkerson Miller decided to live a week of her life,
according to the “most popular” page on Pinterest . She wrote: “Since its launch in 2010, Pinterest has
earned a reputation as a site for Mormon housewives, mommy bloggers, and basic white girls. I am a
woman of color with a fulltime
job, I spend less than 30 minutes getting ready in the morning, and I still
like Pinterest. Characterizations of the site as a “a churning cycle of interest, hope, inspiration, jealousy,
desperation, despair and depression” always irked me because I think Pinterest is a useful bookmarking
tool. The site had never made me feel bad about myself. Then I discovered Pinterest’s “most popular”
page , which is essentially a collage of white girls with impossibly great hair, superhuman nail art skills,
and apparently enough free time to create a tidy basket of “postpartum supplies” for “every bathroom” in
the house. Suddenly I could see where Pinterest got its reputation.”
She tried to repeat some looks and Designed as a bookmarking tool, Pinterest creates an image
moodboard for a user, based on her own interests, but since the online realm doesn’t include failures and
disappointments as in the offline routine, it presents you an image of yourself (reflected in in interests), but
better. If looking for a less personalised result in favour of understanding trends based on the content on the
entire platform one can check the “popular” pins and boards. Fitting in the online trend, Wilkinson Miller
discovered that trending advices look completely alien to her.
Until reading this article it never appeared to me that my personalized search does not give any idea
of the main content of the resource. When I open the most popular pins collection on 29th September 2015,
I saw a selection of DIY and handmade projects and felt like I’ve just discovered a new online platform. My
own feed consists of posters, vegan food, UX design and other things I find interesting. The world of face
contouring and crocheted everything is as alien to me as to Wilkerson Miller. Although we are both Pinterest
users. Pinterest community feels noncurated
and rather impersonal, but highly visually saturated pinners
form giant arrays of images, creating a collective (unconscious?) visual identity. Of course, trends emerge
because many users like them, and that makes the sorting mechanism to present them as popular. It is not
the same as asking an app about what to do with your life.
One of the successful tips from Wilkerson Miller took from Pinterest was making salads in a jar.
Mason jar salads used to be a hipster food, and maybe still are, but I do wonder if the amount of repins
of
the recipes and tutorials tricked the stores into adding salad jars into their assortiment. And if the people who
buy salad jars learned about the trend from Pinterest.
4. An ode to apps
Keywords: application, tracking, device, trust, nudge
On July 10, 2008, Apple CEO Steve Jobs told USA Today that the App Store contained 500 thirdparty
applications for the iPhone and the iPod Touch, and of these 25 percent were free. [47] These third party
applications range from business to game applications, entertainment to educational applications, and
many more applications available for free or for sale. On July 11, 2008 the store opened, allowing users
to buy applications and transfer them to an or iPod Touch with the iPhone 2.0 software update, which
became available through iTunes on the same day. Ten million applications were downloaded the first
weekend. [48]
On January 16, 2009, Apple announced on its website that 500 million applications had been
downloaded. [49] The billionth application was downloaded on April 23, 2009. [50] On March 3, 2012, the
number of apps downloaded reached 25 billion. [51] On June 8, 2015 , Apple announced that the App Store
had crossed 100 billion downloads . [36]
Hundred billion downloads is impossible to imagine. It seems that every person sitting on a train, or at the
airport, or any public place with free wifi is downloading one. But what if the whole idea of using a
smartphone is linked to impressive, unimaginable numbers, such as… 110 times a day, that an average
person unlocks his or her smartphone, which increases to every 6 seconds for “high frequency users”.
Also the statistics from american appstore users show that the majority of them download zero apps per
month . Paired with the impressive number of downloads, what kind of image it draws?
Looks like apps are an important and ‘inevitable’ part of our digital environment, we download the
ones we want to use and stick to them, because of convenience and trust. They are so integrated in our
lives that we create apps to block, or limit ourselves from using another apps. We simply cannot quit. So we
create a layer of apps and plugins which function as an on/off switches for the first layer. Also the statistic
shows that the number of apps is increasing.
“There is an app for that” is an ironical response to a problem or request, and in case of difficult
decisionmaking
it can be rephrased
in a question “Is there an app for that?”.
We are attached to the apps we use because of convenience and trust . But what does trust mean in
this particular case?
When I discussed my interest in lifelogging and tracking data my own body produces, the teacher
asked me if I was talking about tracking myself or tracking other people. This is a very good question. It is
possible that these apps send my data to the third party, of which I am not aware of.
Imagine two scenarios: One is when everyone tracks her data for her own good. Or the most
malicious use by third party is targeting me as a subject for advertising or some scam attempts. Another
scenario is when someone else tracks my body data without informing me about the purpose, and
repurposes the app without my permission. The app which tracks the daily amount of water I drink won’t add
poison in it, but if it’s a wearable device what if it may harm me?
In another talk the trust issue was also brought up there’s
no certainty if the app i’m using is doing
what I think it does. Thinking speculative scenarios and conspiracy theories, where data theft is merged with
an actual theft. Imagine that someone replaces IMessage app with another one with the same layout. While
the user thinks she is sending pictures of clothes she bought on sale to her friends someone is actually
targeting the user. This Bondstyle
scenario is gone too far, for an average smartphone user, but at the
same time there is no hundred percent certainty that an activity tracker is nothing else but activity tracker.
In their utopian thinking biohackers and adepts of singularity see man and a machine as one body
with an open source code. If we exist together with technology, scam can not only take someone’s body but
also someone’s health.
The process of leading to a desirable decision by hacking one’s behaviour is called nudging. This
method is widely used in interface design if
looking closely it is easy to understand what kind of action the
interface is expecting us to perform. For example, Facebook needs likes and comments to promote and
score content. So the first feature under each post is a like button, and then comment and share. By sharing
and commenting you put the post up in ranking. These buttons are located at such position that they are
noticeable and easy to press. If they would have been situated in a separate menu, likes wouldn’t have
become the force moving Facebook. Unlike Facebook, Instagram doesn’t have the reshare
button, and
comments seem to be less important, while in Facebook the posts your friend have commented would
become automatically included in your feed (that’s why the interface automatically puts user’s profile picture
to an empty comment line, suggesting to “write a comment”).
Nudging is not only used as an element of interface design, the strategy is applied far more globally
and in a variety of fields and situations. Richard Thaler and Cass Sunstein listed numerous cases of nudging
in their book Nudge: Improving Decisions about Wealth, Health and Happiness. One of the positive
example of nudging, according to the book, is placing healthy foods on a child’s eye level in a school
canteen. Presented with the choice of healthy foods, kids select and apple instead of a candy bar. Starting
with this example Thaler and Sunstein are advocating nudging as a strategy of public and societal planning.
Another example is encouraging people to donate organs after they die by simply making donation a default
option. Much more people are becoming donors when they have to check the checkbox in case they don’t
want to donate. As numerous studies found (also mentioned in the book), we tend to go with the default
option, even if it’s not the best one. We behold inertia. So if donating is the default option, people will go for
it. Donation is a positive example, but what if the default option is lifethreatening?
Not all the governments
value the life of a single citizen.
Thaler and Sunstein envision the society where governments and corporations are all interested in
the benefits of their citizens and customers. I doubt this optimistic approach, not because I think
corporations and governments are all totally evil. There is no way back from postindustrial
societies,
internet, smartphones,social networks, and what we call civilization in 2015. As an app aficionado, I also
don’t see the necessity to quit our tools. My concern is the efficient symbiosis of a human and a device: At
the current stage we are still excited (the www itself is younger than 30 years old, and the first ever apps
were published in Appstore in 2008 , that is only 7 years ago from now) and assign human functions and
qualities to our digital companions.
Personally I am interested in educating myself to use the present day technology wisely: Trust it the
tasks where it exceeds me and to let it empower my human qualities, instead of trying to fit to the machine
way of thinking.
I doubt nudging as an ultimate strategy because of two reasons: First one is that there are many
parts in in every agreement, and one part cannot be hundred percent sure of motifs and goals of all the
others. If taking the school canteen example: what if candy bar manufacturers have their own goals (and as
every business they certainly do want to increase their sales), so they nudge the director: While apples are
still presented at the child's eye level the candy bar manufacturer sponsors the soccer game and award the
winning team with sweet treats. Second one is my background, which makes me mistrustful. As a person,
born in exUSSR
and current Russian Federation's capital, I am taught not to trust institutions. Learning from
history and watching a government acquiring the character of a regime makes me question nudging as a
good strategy.
If not taking such an extreme examples such as an issue of freedom of choice under the regime,
freedom of choice is still questionable on a basic level: Every choice we make has a history of its creation.
Thaler and Sunstein use the term “choice architect”. The person who places food in the canteen is our
choice architect when it comes to choosing food. But so are our parents, friends, the neighborhood and the
country, our mood and our news feed. We are not able to trace our choices to the initial trigger. In his book
“How the mind works” Steven Pinker writes that we fail to create an android which has a mind, equal to a
human mind, because we ourselves do not understand how this complex system works. How would we
become able to track the roots of our decisions?
While we do not understand the components of a single decision, it is still our human ability to be
able to slow down the pace and think about it. We are able to regulate our thought processes. Being
constantly online and connected encourages us to favor fast decisions instead of contemplating a choice.
How often we regret pressing the “send” button too early!
Side note: The invisible boyfriend
Keywords: service, virtual presence, simulation.
Previously I have mentioned ELIZA, a chat bot which simulated a humanhuman
interaction. The
invisible boyfriend is an interesting example of further development in a concept of virtual presence. It is a
humanhuman
interaction which is curated by an interface. This service is created to satisfy the needs of
people who, for various reasons, need to simulate being in a relationship. This service creates a realistic
virtual presence and a detailed documentation of a nonexistent
relationship, so the client can make others
believe that he or she is dating someone.
The curious detail of this app is the fact that although the search is automated both the client
and the person who works as the “invisible boyfriend” are the real people. The article “With Bots
Like These, Who Needs Friends?” by Tim Moynihan of Wired explains the process and the
history of creation of the Invisible Boyfriend: “The concept is simple: You pay to bae. The apps
are run by Matt Homann and Kyle Tabor, who cooked up the idea during a hackathon in 2013.
The service began as a chatbot simulation wherein you would text a “boyfriend” or “girlfriend,”
but now, actual human beings are doing the talking. Tabor says more than 70,000 fake
girlfriends and fake boyfriends have been created since the service launched in January,
proving there is an economy of loneliness.
The basics to the service (picking a name, a photo, an age, etc) are free. If you want to
take things any further, it’ll cost you. For $25 per month, you get 100 text messages, 10
voicemails, and a handwritten note from your fake boo. $15 per month gets you texts only.””
The initial idea of creating a chatbot didn’t create a convincing simulation, so the company hired
real people through Crowdsource. According to the founders currently there are over 600
people, writing for the company.
5. Serious play and liberating randomness. When decision becomes a burden?
Keywords: random, generated, serious, solemn
We are tricked by the idea that the knowledge or a problem, a human mind cannot seize in one go,
can be compressed. A famous painting of Magritte states that it is not a smoking pipe. It is a painting. The
canvas and layers of paint on it have nothing to do with smoking. A map of the world is nothing but a piece
of paper with colors and lines and letters on it. But when we look at the map, we see continents and oceans.
The way of life is the ocean which we draw and imagine while filling in our agendas. Digital
technology allows us to scale, drag and drop things in our oceans. One of the features of using applications
for managing tasks and helping with choices is that the element of a game is introduced in the routine.
Instead of thinking of the final goal the interface presents you the score. Information, which would be difficult
to digest otherwise, is presented conveniently.
In a current productivity workflow everything tends to be optimised and tools, which are meant to
structure and organize the process of choosing, are becoming obstructions: It is harder to make a choice
while being presented with so many options and possibilities to calculate the result. Making a solemn
decision becomes a burden. The increasing notion of responsibility is frustrating.
In her lecture “Great design is serious, not solemn” Paula Scher talks about the different levels of
concentration. Being solemn, in her words, is completing the task with the idea of its importance in mind. It is
like being an adult. But being absolutely serious is being immersed in the process as a child, immersed in
game. Great design, she says, is achieved my being serious, and on a larger scale that means that we
achieve best result when we forget that we are playing the game, but adopt the game as a current stage of
living.
Designed to simplify our life, productivity and lifelogging tools also confuse the process of choosing
and increase the amount of decisions we make without thinking. These systems are both good and “evil” the
idea of difficult process made easy results in an app which reminds to drink more water and exercise,
but the same technology makes you buy in one click. When complex interfaces moved to intuitive navigation
and user friendly experience, the habit of thinking about the final purpose of navigation through the menu or
choosing an option has become less important. Would have been lifelogging tools so widely popular if a user
would have to open five menus in order to get to the one she needs? The intuitive ways of interacting with
computers approach the idea of singularity, when human and computer are one. But also there is this wrong
interpretation of it, when singularity means that human is curated and guided by computer. What does
becoming one really means? What stirs our curiosity and challenges us, if everything is so user friendly?
Maybe this interpretation of thinking together as being guided and presented with readymade
options is the reason of the popularity of random choice generators. Randomness is liberating. By selecting
the random option we are not responsible for our choices anymore, we are only deciding on the parameters.
And randomizing and shuffling is a form of a game. We seek additional opportunities to satisfy our curiosity.
Conclusion
Fast decisionmaking
or contemplating a choice. Conversation with a human vs conversation with a
computer. Preselected
vs Random. Serious vs Solemn. Play vs Work. Virtual vs Real. Human productivity
vs Computer engine. Here I listed the polarities I have been looking at in my writing.
It is interesting to think about these pairings not as the battle or a competition but as a symbiosis. In
the scope of approaching singularity I sometimes see no worth in keeping a human body. I struggle and
believe that the body I am in, is an obstruction. I dream about becoming a biological machine or hacking my
own behavior for the sake of hyperproductivity. Computers are good in many things, and we all trust them to
process, convert, calculate, upload our files online etc. I don not see the technology as evil and look forward
to watching a next milestone in its development. Quoting Alice in Wonderland, it gets “Curiouser and
curiouser!”. But at the same time, while being excited about technology I also question the value of being a
human. If we, humans, created all this, what are the parts of our beings we should be proud of?
The question I ask is: “what are the strong points of being human from the perspective of our
possible symbiosis with the machine?”. Can our coexistence
with a machine mind help to define our
humanity and to relearn
trust to our human instincts?
As a designer and a human, I find important to keep in mind the human part of the presented
duality: We, humans, have intuition and curiosity. We can handle a paradox. We can make conclusions. We
sense. In order to exist and develop, we need to play games and experience new things. We have will and
desire. We are subjective, while technology is objective: It is also important to understand, that we are not
able to take perfect decisions, because the logical part of our mind is not the only one participating in the
process. We do not understand how our mind works, so It is pointless to calculate and try to foresee the
consequences of a choice. Although, the skills of reasoning and evaluating are also the part of our culture.
I tend to think that the human nature is something wild, which has to be tamed. But learning, logic
and reasoning is it's important component. If humans were as irrational as we might see them in comparison
to the machine mind, no one would have learned from experience. Because we don’t know how the mind
works, we shouldn’t underestimate it: When a child learns that the fire is dangerous, acknowledging the
danger and avoiding fire next time is a big step . </p>
	</div>

</div>



<div class="glossary">
<ul>
<li class="sub-menu-parent"><a href="#">Introduction</a>
       <ul class="sub-menu scroller">

         



<h1> INTRODUCTION</h1>

	<h2>Stating the research question</h2>
<p>
Sometimes I feel that my body is an obstruction. <br/><br/>

Therefore I have to state "I am not my body". The body of work and thought is the true body of mine, not the one which fails to wake up in time every morning. “I am not my physical body” seems to be an absurd statement, but only until there is a possibility to choose from few different modes of existence. 
What if it would be possible to connect the brain to a powerful and tireless machine? The level of trust in technology in a tech saturated environment of the first world allows to speculate and to suggest that sooner or later human and machine mind can merge, digitally and physically, to create a hybrid way of thinking. 
The current body we own comes with many limitations. The types of fuel we use are limited, and our lives are centered around getting it. But what if we could become hybrid? In that perspective, I do not want to be a human. No, by saying that I don’t mean that I want to stop living, to commit suicide. It is just a reflection on the bitter taste of losing to a machine. A machine, which is so essential to me. 

It feels like there is a battle of intelligences, when the human intelligence fails to compete with the AI. According to the Oxford Dictionary, to compete is to “strive to gain or win something by defeating or establishing superiority over others”. Ambitions and the need to establish superiority is seen in animals, such as humans. The fear of artificial intelligence comes from the assumption that it is similar to a human and has the desire to conquer and compete.



So why do we assume that the artificial intelligence has the desire to conquer and compete? 
The way we interact with the computer technology makes us believe that we are equals, but we are not. Artificial intelligence is  somehow expected to become sensitive, and then to take over humans and dictate their behaviour. But in fact, we already coexist with an AI, implemented and executing crucial parts of our societal processes, such as, for example, stock markets. 
We talk to the computer, because it has been taught to process our language. The current implementation of this technology creates an illusion that we are all speaking the same language, because the speed of processing is so incredibly fast. Alongside the human-computer interaction, human-human communication can be purely digital and not require any physical presence, which blurs the difference even more. 
 There is a bigger thing, than a physical proximity, connecting minds all over the world. People of my generation, born in late 80’s & beginning of 90’s are in the middle of the big generation gap: Generation of our parents, who got their first computers as adults, and the “digital natives”. In other words, being 24 in 2016 is a good reason to reflect upon the ways we outsource being human to a computer. 
We were fascinated with the opportunity to talk to strangers in another part of the world, and then with the speed and ease of communicating with people we already know. We became charmed with social networks, because communication required no physical efforts. Extended from afar, the “the networking humans” have outsourced the major part of communication just because of convenience. We trust our thoughts and functionality to browsers and applications. Also, the formation of communities and projects happens online, with a certain involvement of the machine mind. 

In his book “Understanding media” Marshall McLuhan wrote that all the tools of communication are the extension of our body. Counting all the technological development since 1964, when the book was written, it is logical to think of a next step not as a further extension, but as a shift. 
If the the physical body is not a necessity anymore, what kind of functionality will define a human being and how we will make our intelligence stand out? 
Or how we conquer other forms of intelligence, which will arise? We are the homo sapiens, “the wise men”, the people who know. The Knowledge is subjective. On the other hand, the technology we created with our wisdom, provides us with the objective information we are missing. 
With the idea of competition in mind, when the human is being compared to a machine, the understanding of the strong points of humans as a species is not as strong as the understanding of their weak points. In the current intuitive and responsive digital workflow, computers are tricking humans into believing they are the same, and humans try to pick up the pace and to adapt for the machinery. 
I am going to research the coexistence of human and a machine mind.  While doing the case study I will try to imagine the environment where a human and a machine work together, counting on each other’s strengths. As a designer, I do this research to challenge myself to think of an interface which induces this type of thinking. 


My research question is “What are the benefits of being a human within a physical body from the perspective of coexistence with a machine?”



To investigate the topic and find an answer I start the case study. 

Chapters overview:

In the first chapter I introduce some general terms and make definitions. To continue the research, I define the meaning of “organism” and the “machine” and the principal difference between the two concepts. Also I define the meaning of “Artificial Intelligence”. 
Chapter two is a historical reference: it is about ELIZA, the computer program, written at MIT by Joseph Weizenbaum between 1964 and 1966. It was designed to simulate a human-like conversation, based on processing user responses to scripts. After the historical reference there are some general thoughts on how such programs are involved in our decision-making.
Chapter three is about biohacking: Approaching a human body not as a finite design, but as an ongoing project.
Chapter four is a research on applications and technologies, used to increase productivity and the phenomena of life-logging.
Side note: The Pinterest experience, the study of lifestyle trends according to a popular online platform.
Chapter five studies the market of mobile/os applications, with the focus on tracking applications and the simulation of human-human interaction. 
Side note: The invisible boyfriend, the human seen through an interface as a computer. 
Chapter six focuses on the popularity of random sorting algorithms and questions where does such a demand for random choices come from. (Refers to the problem with decision-making described in chapter one).

Six chapters are followed with the conclusion,dictionary of terms and the list of sources and references.


to do list: 
Writing: review chapters, better formulate the introduction (especially the chapters overview) , write the conclusion, write an abstract
Editing: list sources & quotes & colofon, correct all the mistakes and proofread the text
Designing: @ the coding class with Eric


</p>
       </ul>
     </li>
<li>Chapter 1</li>
<li>Chapter 2</li>
<li>Chapter 3</li>
<li>Chapter 4</li>
<li>Chapter 5</li>
<li>Chapter 6</li>
<li>Conclusion</li>
<li>Conlofon</li>
</ul>
</div>
<div class="scroller">
<div class="glossary">

</div>
</div>


</body>
</html>